<!DOCTYPE html>
<html>

<head>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <style>
        p {
            font-size: 20px;
            font-family: Verdana, Geneva, Tahoma, sans-serif;
        }

        html,
        body {
            height: 100%;
        }

        img {
            width: 100%;
        }

        img.two {
            height: 50%;
            width: 40%;
        }

        /* .column {
            float: left;
            width: 50%;
            height: 50%
        } */

        /* Clearfix (clear floats)
        .row::after {
            content: "";
            clear: both;
            display: table;
        } */

        .center {
            display: block;
            padding-top: 2%;
            margin-left: auto;
            margin-right: auto;
            width: 50%;
        }

        .button {
            position: absolute;
            background-color: #f44336;
            text-decoration: none;
            cursor: pointer;
            display: inline-block;
            left: 1000px;
            top: 30px;
        }

        .col-6 {
            text-align: center;
            align-self: center;
        }

        table {
            font-family: arial, sans-serif;
            border-collapse: collapse;
            width: 100%;
        }

        td,
        th {
            border: 1px solid #dddddd;
            text-align: left;
            padding: 8px;
        }

        tr:nth-child(even) {
            background-color: #dddddd;
        }

        .section-container {
            padding: 20px 0px;
        }

        .section-content {
            padding-top: 40px;
        }
    </style>
</head>

<body>
    <div class="container">
        <section style="padding-top: 10px;">
            <h1 style="text-align: center;font-size: 45px;">US Airline Sentiment Analysis Report</h1>
        </section>
        <section style="text-align: center;">
            <div style="padding: 10px 0px;">
                <i>By: Shreyansh Dhandhukia, Jimmy Tran, Naveen Muthusamy</i>
            </div>
           <div>
            <button onclick="window.open('https://airlines-sentimental.netlify.app/','_blank');"
            class="btn btn-danger">Website</button>
        <button onclick="window.open('https://github.com/jimmytran16/CS438-ML-Project/','_blank');"
            class="btn btn-primary">Source Code</button>
        <button onclick="window.open('https://docs.google.com/presentation/d/1ftBJrxIIhHKLs-FV0p_4uRGDWso7vUaaqgMNL7o9N48/edit?usp=sharing','_blank');"
            class="btn btn-warning">Presentation</button>
           </div>
        </section>
        <section class="section-container">
            <h1>About the project</h1>
                <p>In this project we analyzed user tweets about airline performance in the US. We cleaned and preprocessed
                    the data and finally train Machine learning models to analyze Sentiment of the tweets and return
                    whether a tweet is positive, neutral or negative. The dataset was trained on three classifiers namely
                    logistic regression, Support Vector Machines and Neural networks. Later we plotted learning curves, 
                    performance curves and compared them based on their accuracy,
                    precision and F1 score.</p>
        </section>
        <section class="section-container">
            <div class="section-content">
                <h1>Why do we need Sentiment Analysis?</h1>
                <p>1. We need it to enhance the customer service, as we need to learn what customers are happy about and what 
                    frustrates them.  </p>
                <p>2. By Sentiment analysis we can improve products and services given to the customer and also fix the 
                    issue and bugs present in the current product.  </p>
                <p>3. Using Sentiment Analysis one can optimize the marketing strategy so as to implement which steps to 
                    boost the sales of the company.
                </p>
                <p>4. With Sentiment Analysis one can monitor the brand reputation of the firm.</p>
                
            </div>
        </section>
        <section class="section-container">
            <h1> Understanding the Dataset </h1>
            <p>The dataset contains <b>14640 tweets</b> and 15 features namely:
                Tweet_id,
                Airline_sentiment (positive/negative/neutral),
                Airline_sentiment_confidence,
                Negative reason,
                Negative_reason_confidence,
                Airline,
                Name (Person who tweeted),
                Retweet_count,
                Text (tweet),
                Tweet_created,
                tweet_location. 
                <br>
                <br>
                However we found that there was an imbalance of sentimental tweets, and so to avoid model biasing we implemented a 
                simple approach to handle data imbalance. This approach imvolves duplicating examples in minority class, this type 
                of data augmentation for the minority class and is referred to as the <b>Synthetic Minority Oversampling Technique, 
                or SMOTE </b> short. So, our dataset now had <b> 27534 tweets </b> in total, with almost equal number of tweets 
                for each of the three classes.

            </p>
            <div class="row">
                <div class="col-6">
                    <img src="images/Null Values.png" alt="Null values in dataset">
                </div>
                <div class="col-6">
                    <img src="images/Sentimental Doughnut Chart.png" alt="Null values in dataset">
                </div>
            </div>

            <div class="row">
                <div class="col-6">
                    <img src="images/Total tweet for each airline.png" alt="Null values in dataset">
                </div>
                <div class="col-6">
                    <img src="images/Reason for negative tweets.png" alt="Null values in dataset">
                </div>
            </div>

            <div class="row">
                <div class="col-4">
                    <img src="images/Negative Reasons - American.png" />
                </div>
                <div class="col-4">
                    <img src="images/Negative Reasons - Delta.png" />
                </div>
                <div class="col-4">
                    <img src="images/Negative Reasons - Southwest.png" />
                </div>
            </div>
            <div class="row">
                <div class="col-4">
                    <img src="images/Negative Reasons - United.png" />
                </div>
                <div class="col-4">
                    <img src="images/Negative Reasons - US Airways.png" />
                </div>
                <div class="col-4">
                    <img src="images/Negative Reasons - Virgin America.png" />
                </div>
            </div>
        </section>

        <section class="section-container">
            <h1>Architecture of System</h1>
            <div class="section-content">
                <img src="images/Architecture of System.png" alt="Null values in dataset">
                <p>This web application that we created for this ML project is a Clent-Server architecture. We use
                    React for
                    the front-end and have currently hosted our system on netlify.</p>
                <p>For the server we use flask as a web server to serve airline data to the client i.e. our browser. To
                    make the website available
                    to all the users we have hosted the website on Heroku. The server's job is to parse the dataset and
                    then
                    send the data to client
                    for visualization. We are using the library pandas in order to parse our dataset that is coming from the CSV file. 
                    We are also sending the data to the python file <i>(process.py)</i> for preporcessing and training purposes. Here,
                    we preprocess the data and send the training data sets to the three machine learning classifiers, namely Logistic Regression, 
                    Support Vector Machines and Neural networks, using the Sklearn framework (<a href="https://scikit-learn.org/stable/index.html" target="_blank">here</a>) to train our Machine learning models and well as 
                    cleaning the dataset.
                </p>
            </div>
        </section>
        <section class="section-container">
            <h1>Machine Learning Models</h1>
            <div class="section-content">
                <h3>1. Logistic Regression</h3>
                <p>Logistic Regression uses a decision threshold to to classify the dataset. The setting of the
                    threshold
                    value is a very important
                    aspect of Logistic regression and is dependent on the classification problem itself. In our project
                    we
                    use multinomial logistic
                    regression for this problem as it has more than two possible discrete outcomes(Positive, Negative,
                    neutral). The model predicts
                    the probabilities of the different possible outcomes of a categorically distributed dependent
                    variable,
                    given a set of independent
                    variables.
                </p>
                <p>One of the major aspects of training your machine learning model is avoiding overfitting.
                    Regularization,
                    significantly reduces
                    the variance of the model, without substantial increase in its bias.So to avoid the risk of
                    overfitting
                    in
                    our model we performed regularization. Some of the regularization techniques used to address
                    overfitting
                    are L1(Lasso Regression)
                    and L2 (Ridge Regression). For our model we used L2 regression as it adds “squared magnitude” of
                    coefficient as penalty term to
                    the loss function which lessens the overfitting for us significantly.
                </p>
                <p> F1-score: 0.98 Acuracy: 0.94 </p>
                <p>Learning curves with tuning and regularization</p>
                <img class="two" src="images/Learning curves LR with tuning.png" alt="Null values in dataset">
                <img class="two" src="images/Scability of LR with parameter tuning.png" alt="Null values in dataset">
                <br>
                <img class="two" src="images/Performance of LR.png" alt="Null values in dataset">
                <img class="two" src="images/Confusion Matrix LR with tuning.png" alt="Null values in dataset">
            </div>

            <div class="section-content">
                <h3>2. Support Vector Machines (SVM)</h3>
                <p>
                    SVM is a simple Supervised Machine Learning algorithm used for mostly for classification. It is
                    basically a representation of
                    classes in a hyperplane in multi-dimensional space. SVM maps training examples to points in space so
                    as
                    to maximise the width
                    of the gap between the two categories. New examples are then mapped into that same space and
                    predicted
                    to belong to a
                    category based on which side of the gap they fall For multiclass classification, the same principle
                    is
                    utilized.
                </p>
                <p>
                    One of the major aspects of training your machine learning model is avoiding overfitting.
                    Regularization, significantly reduces
                    the variance of the model, without substantial increase in its bias. So, to avoid overfitting we
                    tuned
                    our model with different
                    "param_grid = {'C': [10, 100], 'gamma': [1,0.1,0.01],'kernel': ['rbf', 'poly', 'sigmoid']}". By
                    training
                    our SVM with these
                    parameters we were able to find that C=100 and gamma=1 was the best possible combination of
                    parameters
                    which gives better accuracy.
                </p>

                <p> F1-score: 0.99 Acuracy: 0.95 </p>

                <p>Learning curves with tuning and regularization</p>
                <img class="two" src="images/Learning Curve SVM.png" alt="Null values in dataset">
                <img class="two" src="images/Scability of SVM.png" alt="Null values in dataset"> <br>
                <img class="two" src="images/Performance of SVM.png" alt="Null values in dataset">
                <img class="two" src="images/Confusion Matrix SVM.png" alt="Null values in dataset">
            </div>
            <div class="section-content">
                <h3>3. Neural Networks</h3>
                <p>
                    Neural networks take inspiration from the learning process occurring in human brains. They consists of an artificial network of functions, called parameters, which allows the computer to learn, and to fine tune itself, by analyzing new data. 
                    Each parameter, sometimes also referred to as neurons, is a function which produces an output, after receiving one or multiple inputs. Those outputs are then passed to the next layer of neurons, which use them as inputs of their own function, and produce further outputs. 
                    Those outputs are then passed on to the next layer of neurons, and so it continues until every layer of neurons have been considered, and the terminal neurons have received their input. Those terminal neurons then output the final result for the model.
                </p>
                <p>
                    One of the major aspects of training your machine learning model is avoiding overfitting.
                    Regularization, significantly reduces
                    the variance of the model, without substantial increase in its bias. So, to avoid overfitting we
                    tuned
                    our model with different
                    "hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500". By
                    training
                    our Neural Network with these
                    parameters we were able to acheive best accuracy.
                </p>

                <p> F1-score: 0.93 Acuracy: 0.93 </p>

                <p>Learning curves with tuning and regularization</p>
                <img class="two" src="images/Learning Curve - NN.png" alt="Null values in dataset">
                <img class="two" src="images/Scalability - NN.png" alt="Null values in dataset"> <br>
                <img class="two" src="images/Performance - NN.png" alt="Null values in dataset">
                <img class="two" src="images/Confusion Matrix - NN.png" alt="Null values in dataset">
            </div>
        </section>
        <section class="section-container">
            <div class="section-content">
                <h1>Talking about the models</h1>
                <p>1. After succesfully implementing all the three models we observed that, the accuracy of the tuned Support Vector
                    Machines is even better than neural networks without regularization and Logistic Regression with Regularization
                    and parameter tuning. 
                </p> 
                <p>2. After tuning the Logistic Regression the accuracy of the model shoot from 90% to 94% which clearly describes
                    the importance of hyperparameter tuning.
                </p> 
                <p>3. The accuracy of the SVM after tuning shoot to 95% from 94%.</p>
                <p>4. We also plotted the accuracy scores of all the three models, and according to the plots the accuracy of the
                    model for cross-validation set increases as the number of cross-validation dataset increases. 
                </p>
                <p>5. We also plotted the performance of the model graph which is a plot between score and fit_times
                    (Times spent for fitting in seconds.). This activity can be crucial when 
                    the user is still trying to optimize the model and make it production ready.</p>
                <p>6. Lastly, we also plotted confusion matrix to viusally understand the comparison of values like 
                    True Positives, False Positives, True Negatives and False Negatives and visually observed that 
                    in our implementation Tuned SVM was the most accurate and robust model out of all other models.
                </p> 
            </div>
        </section>
        <section class="section-container">
            <div class="section-content">
                <h1>Challenges Faced</h1>
                <p>1. One of the major challenge we faced was of model biasing as we had less number of tweets for positive and
                    neutral sentiments. However, we then searched through the web for different techniques used to handle 
                    data imbalance and implemented <b>Synthetic Minority Oversampling Technique, 
                        or SMOTE </b> in our project. </p>
                <p>2. The second challenge which we faced was to setup up the configurations for the production server to host 
                    the website properly so as to make it available to everyone during our class presentation.  </p>
                <p>3. The third challenge was to create an algorithm to be able to structure the training data set from the CSV 
                    in order to properly satisfy what the front end is expecting</p>
                <p>4. Lastly learning about the SKLearn framework to successfully implement the Machine Learning models.</p>

            </div>
        </section>
        <section class="section-container">
            <div class="section-content">
                <h1>Error Analysis</h1>
                <p>1. One of the reason of facing error in preditcion may be; if a user tweets something sarcastic. A sarcasm
                    may not count in negative word and the classifier may detect it as a positive or a neutral tweet.
                </p>
                <p>2. Some of the words can be positive and negative based on the context of language. So, traditional ML models
                    may not be able to detect it.
                </p>
            </div>
        </section>
            <section class="section-container">
                <div class="section-content">
                    <h1 id="work-distrubution">Resources</h1>
                    <p>This is a list of resources we used for creating this project</p>
                    <table>
                        <tr>
                            <th>Description</th>
                            <th>Link</th>
                        </tr>
                        <tr>
                            <td><b>Sklearn</b> - A Python framework used for training Machine Learning Models</td>
                            <td><a href="https://scikit-learn.org/stable/index.html" target="_blank">https://scikit-learn.org/stable/index.html</a></td>
                        </tr>
                        <tr>
                            <td><b>Pandas</b> - A Python library used for parsing the training data set from CSV file</td>
                            <td><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html" target="_blank">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html</a></td>
                        </tr>
                        <tr>
                            <td><b>Flask</b> - A Python framework used as a web server to serve data to the UI for data visualization</td>
                            <td><a href="https://flask.palletsprojects.com/en/2.0.x/" target="_blank">https://flask.palletsprojects.com/en/2.0.x/</a></td>
                        </tr>
                        <tr>
                            <td><b>React.js</b> - A Javascript framework used as the front end to render the data visualization</td>
                            <td><a href="https://reactjs.org/docs/getting-started.html" target="_blank">https://reactjs.org/docs/getting-started.html</a></td>
                        </tr> 
                    </table>
                </div>
            </section>
            
        <section class="section-container">
            <div class="section-content">
                <h1 id="work-distrubution">Work Distrubution</h1>
                <p>This is the table that demonstrates the shared work for this Machine Learning project</p>
                <table>
                    <tr>
                        <th>Name</th>
                        <th>Work</th>
                        <th>Hours</th>
                    </tr>
                    <tr>
                        <td>Shreyansh Dhandhukia</td>
                        <td>
                            <ul>
                                <li>Parsing the data from the training data file to distribute to the machine
                                    learning models</li>
                                <li>Text processing and data cleaning</li>
                                <li>Plotting learning curve</li>
                                <li>Created a component in the UI to retrieve data from the server to render the graphs</li>
                                <li>Tuned and worked on SVM and Logistics Regression</li>
                            </ul>
                        </td>
                        <td>40 hours</td>
                    </tr>
                    <tr>
                        <td>Jimmy Tran</td>
                        <td>
                            <ul>
                                <li>Implemented the web application's UI, using React/Javascript</li>
                                <li>Wrote parsing functionality to parse training data set for sending to UI for displaying and for data processing</li>
                                <li>Created the server that feeds the data to the UI</li>
                                <li>Implemented, trained, and processed the dataset for the Support Vector Machine model</li>
                            </ul>
                        </td>
                        <td>40 hours</td>
                    </tr>
                    <tr>
                        <td>Naveen Muthusamy</td>
                        <td>
                            <ul>
                                <li>Data regularization</li>
                                <li>Neural Network Implementation</li>
                                <li>Data balancing with SMOTE</li>
                            </ul>
                        </td>
                        <td>40 hours</td>
                    </tr>
                </table>
            </div>
        </section>
    </div>
</body>

</html>
